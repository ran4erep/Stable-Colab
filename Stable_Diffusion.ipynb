{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ran4erep/Stable-Colab/blob/main/Stable_Diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKe1AR4FFMr9"
      },
      "outputs": [],
      "source": [
        "# @title Установка Stable Diffusion и подключение Google Drive: { vertical-output: true, form-width: \"100%\", display-mode: \"form\" }\n",
        "# @markdown Хотите исользовать Google Drive?\n",
        "use_gdrive = False # @param {type:\"boolean\"}\n",
        "import os\n",
        "import torch\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "if use_gdrive:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  print(\"GDrive sucessfully mounted to /content/gdrive\")\n",
        "  # Создаём папку в Google Drive, если её нет\n",
        "  if not os.path.exists(\"/content/gdrive/MyDrive/SDOutput\") and use_gdrive:\n",
        "    os.makedirs(\"/content/gdrive/MyDrive/SDOutput\", exist_ok=True)\n",
        "    print(\"Успешно создана папка /content/gdrive/MyDrive/SDOutput\")\n",
        "else:\n",
        "  print(\"Google Drive не подключен\")\n",
        "\n",
        "!pip install diffusers[\"torch\"] transformers\n",
        "!pip install accelerate\n",
        "!pip install git+https://github.com/huggingface/diffusers\n",
        "\n",
        "#from diffusers import StableDiffusionPipeline\n",
        "from diffusers import AutoPipelineForText2Image\n",
        "from diffusers import (\n",
        "    DDPMScheduler,\n",
        "    DDIMScheduler,\n",
        "    PNDMScheduler,\n",
        "    LMSDiscreteScheduler,\n",
        "    EulerAncestralDiscreteScheduler,\n",
        "    EulerDiscreteScheduler,\n",
        "    DPMSolverMultistepScheduler,\n",
        ")\n",
        "from diffusers.utils import make_image_grid"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Подготовка Stable Diffusion: { vertical-output: true, form-width: \"100%\", display-mode: \"form\" }\n",
        "# @markdown\n",
        "# @markdown В переменной **current_checkpoint** указываем чекпоинт модель с HuggingFace,  взять её можно на [CivitAI](https://civitai.com/models). При поиске моделей, в фильтре, ставим галочку только на checkpoint.\n",
        "# @markdown\n",
        "# @markdown  Потом уже заходим на [HuggingFace](https://huggingface.co/models?library=diffusers) и ищем там понравившеюся модель по её названию с CivitAI. Копируем это название и вставляем в значение переменной **current_checkpoint**.\n",
        "\n",
        "!nvidia-smi\n",
        "\n",
        "####################\n",
        "# Список опробованных мною моделей:\n",
        "# PicX_real:     GraydientPlatformAPI/picx-real\n",
        "# Juggernaut:    digiplay/Juggernaut_final\n",
        "# Juggernaut XL: frankjoshua/juggernautXL_version6Rundiffusion\n",
        "# RealVisXL 3.0: SG161222/RealVisXL_V3.0_Turbo\n",
        "####################\n",
        "\n",
        "# @markdown Текущая модель:\n",
        "current_checkpoint = \"GraydientPlatformAPI/picx-real\" # @param [\"digiplay/Juggernaut_final\", \"GraydientPlatformAPI/picx-real\", \"frankjoshua/juggernautXL_version6Rundiffusion\", \"SG161222/RealVisXL_V3.0_Turbo\"] {allow-input: true}\n",
        "# @markdown Текущее устройство:\n",
        "current_device = \"cuda\" # @param [\"cuda\"]\n",
        "## @markdown Вариант:\n",
        "#current_variant = \"fp16\" # @param [\"\", \"fp16\", \"ema\"]\n",
        "# @markdown Использовать safetensors?\n",
        "use_safetensors = None # @param [\"True\", \"False\", \"None\"] {type:\"raw\"}\n",
        "\n",
        "\n",
        "# Список планировщиков\n",
        "ddpm = DDPMScheduler.from_pretrained(current_checkpoint, subfolder=\"scheduler\")\n",
        "ddim = DDIMScheduler.from_pretrained(current_checkpoint, subfolder=\"scheduler\")\n",
        "pndm = PNDMScheduler.from_pretrained(current_checkpoint, subfolder=\"scheduler\")\n",
        "lms = LMSDiscreteScheduler.from_pretrained(current_checkpoint, subfolder=\"scheduler\")\n",
        "euler_anc = EulerAncestralDiscreteScheduler.from_pretrained(current_checkpoint, subfolder=\"scheduler\")\n",
        "euler = EulerDiscreteScheduler.from_pretrained(current_checkpoint, subfolder=\"scheduler\")\n",
        "dpm = DPMSolverMultistepScheduler.from_pretrained(current_checkpoint, subfolder=\"scheduler\")\n",
        "\n",
        "# @markdown Текущий планировщик:\n",
        "current_scheduler = euler # @param [\"ddpm\", \"ddim\", \"pndm\", \"lms\", \"euler_anc\", \"euler\", \"dpm\"] {type:\"raw\"}\n",
        "\n",
        "# Настройка пайплайна\n",
        "pipe = AutoPipelineForText2Image.from_pretrained(current_checkpoint, torch_dtype=torch.float16, use_safetensors=use_safetensors)\n",
        "#pipe = StableDiffusionPipeline.from_pretrained(current_checkpoint, torch_dtype=torch.float16)\n",
        "pipe = pipe.to(current_device)\n",
        "pipe.safety_checker = None # Отключение NSFW (18+)\n",
        "pipe.scheduler = current_scheduler.from_config(pipe.scheduler.config) # <-- Здесь выбираем планировщик, список в переменных выше"
      ],
      "metadata": {
        "id": "mkHQj8AHJKzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Калькулятор соотношения сторон: { vertical-output: true, form-width: \"100%\", display-mode: \"form\" }\n",
        "# @markdown Исходная ширина\n",
        "calc_width = 0 # @param {type:\"integer\"}\n",
        "# @markdown Исходная высота\n",
        "calc_height = 0 # @param {type:\"integer\"}\n",
        "# @markdown Новая ширина\n",
        "new_calc_width = 0 # @param {type:\"integer\"}\n",
        "answer = (calc_height / calc_width) * new_calc_width\n",
        "\n",
        "answer"
      ],
      "metadata": {
        "id": "5LAOxcH_G4T8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Настройка пайплайна: { run: \"auto\", form-width: \"100%\", display-mode: \"form\" }\n",
        "# Здесь указываем переменные для пайплайна Stable Diffusion\n",
        "# Дефолтный промпт для лучшего качества: (8k, ultra realistic, highly detailed, cinematic lighting)\n",
        "\n",
        "# @markdown Промпт:\n",
        "prompt = \"cat, close-up shot, 8k, ultra realistic, highly detailed, cinematic lighting\" # @param {type:\"string\"}\n",
        "# @markdown Негативный промпт:\n",
        "negs = \"ugly face, canvas frame, cartoon, 3d, disfigured, bad art, deformed, extra limbs, close up, b&w, wierd colors, blurry, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, ugly, blurry, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, out of frame, ugly, extra limbs, bad anatomy, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, mutated hands, fused fingers, too many fingers, long neck, Photoshop, video game, ugly, tiling, poorly drawn hands, poorly drawn feet, poorly drawn face, out of frame, mutation, mutated, extra limbs, extra legs, extra arms, disfigured, deformed, cross-eye, body out of frame, blurry, bad art, bad anatomy, 3d render\" # @param {type:\"string\"}\n",
        "# @markdown Ширина:\n",
        "width = 512 # @param {type:\"number\"}\n",
        "# @markdown Высота:\n",
        "height = 512 # @param {type:\"number\"}\n",
        "# @markdown Количество изображений:\n",
        "images_count = 1 # @param {type:\"slider\", min:1, max:10, step:1}\n",
        "# @markdown Шаги:\n",
        "steps = 50 # @param {type:\"number\"}\n",
        "# @markdown Шкала инструкции:\n",
        "gscale = 7.5 # @param {type:\"number\"}\n",
        "# @markdown Использовать случайный seed?\n",
        "randomness = True # @param {type:\"boolean\"}\n",
        "# @markdown Seed:\n",
        "seed = 4164594511988624 # @param {type:\"integer\"}"
      ],
      "metadata": {
        "id": "V_7uVSOrKytu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KlwVc5EAKuUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Работа Stable Diffusion { vertical-output: true, form-width: \"100%\", display-mode: \"form\" }\n",
        "# Генерация картинки\n",
        "# @markdown <-- Начать генерацию\n",
        "\n",
        "print(\"###############\")\n",
        "print(\"Текущая модель Stable Diffusion: \" + current_checkpoint)\n",
        "print(\"Промпт: \" + prompt)\n",
        "print(\"Негативный промпт: \" + negs)\n",
        "print(\"Разрешение: \" + str(width) + \"x\" + str(height))\n",
        "\n",
        "if not randomness:\n",
        "  generator = torch.Generator(current_device).manual_seed(seed)\n",
        "  print(\"Seed этого изображения: \" + str(seed) + \"\\n###############\")\n",
        "elif randomness:\n",
        "  current_seed = torch.Generator(current_device).seed()\n",
        "  generator = torch.Generator(current_device).manual_seed(current_seed)\n",
        "  print(\"Seed этого изображения: \" + str(current_seed) + \"\\n###############\")\n",
        "\n",
        "result = pipe(prompt, height=height, width=width, num_inference_steps=steps, guidance_scale=gscale, negative_prompt=negs, generator=generator, num_images_per_prompt=images_count)\n",
        "\n",
        "# Вывод и сохрарнение результата\n",
        "\n",
        "if use_gdrive:\n",
        "  for i in range(images_count):\n",
        "    file_name = prompt + \" \" + str(current_seed) + \"___\" + str(i) +\".png\"\n",
        "    temp_path = \"/tmp/image\" + str(i) + \".png\"\n",
        "    image_pil = Image.fromarray(np.uint8(result.images[i]))\n",
        "    image_pil.save(temp_path, \"PNG\")\n",
        "    new_file_name = \"/content/gdrive/MyDrive/SDOutput/\" + file_name\n",
        "    !cp $temp_path /content/gdrive/MyDrive/SDOutput\n",
        "    os.rename(\"/content/gdrive/MyDrive/SDOutput/image\" + str(i) + \".png\", new_file_name)\n",
        "    print(\"Сохранено: /content/gdrive/MyDrive/SDOutput/\" + file_name)\n",
        "\n",
        "#image\n",
        "make_image_grid(result.images, rows=1, cols=images_count)"
      ],
      "metadata": {
        "id": "23njihNOG-du"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}