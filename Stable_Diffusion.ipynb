{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ran4erep/Stable-Colab/blob/main/Stable_Diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "↑ Желательно нажать Файл --> Сохранить копию на Диске\n",
        "\n",
        "Это нужно чтобы все введённые вами данные сохранялись. Например токен для сайта CivitAI, чтобы не копировать и не вставлять его в соответсвующее поле каждый раз.\n",
        "\n",
        "[Видео-инструкция](https://www.youtube.com/embed/VQ3YvX0-9wQ?si=19q0p3cpUpul8lVl)\n",
        "\n",
        "[Ответы на часто задаваемые вопросы и разъяснения по поводу использования LoRA](https://www.youtube.com/embed/-ZI4TH8fjgM?si=QEGKbNAYzPee5RVE)\n",
        "\n",
        "[Обновлённая инструкция по версии 1.4.2](https://youtu.be/klMvuBeYGIU?si=sJUFZkgy4ZxH0KJQ)\n",
        "\n",
        "[Stable Colab 1.5.1: Использование моделей с сайта CivitAI](https://youtu.be/_YtwhJWud40?si=1iPy7uuStUNLa4L3)"
      ],
      "metadata": {
        "id": "A7l39D9u2_De"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKe1AR4FFMr9"
      },
      "outputs": [],
      "source": [
        "# @title Установка Stable Diffusion и подключение Google Drive: { vertical-output: true, form-width: \"10%\", display-mode: \"form\" }\n",
        "# @markdown Хотите исользовать Google Drive?\n",
        "use_gdrive = False # @param {type:\"boolean\"}\n",
        "# @markdown\n",
        "\n",
        "import os\n",
        "import re\n",
        "import torch\n",
        "import gc\n",
        "import sys\n",
        "import shutil\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import io\n",
        "import numpy as np\n",
        "from datetime import date\n",
        "from datetime import datetime\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import display, update_display\n",
        "import ipywidgets as widgets\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from urllib.parse import unquote\n",
        "\n",
        "if use_gdrive:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  print(\"GDrive sucessfully mounted to /content/gdrive\")\n",
        "  # Создаём папку в Google Drive, если её нет\n",
        "  if not os.path.exists(\"/content/gdrive/MyDrive/SDOutput\"):\n",
        "    os.makedirs(\"/content/gdrive/MyDrive/SDOutput\", exist_ok=True)\n",
        "    print(\"Успешно создана папка /content/gdrive/MyDrive/SDOutput\")\n",
        "\n",
        "#!pip install diffusers[\"torch\"] transformers\n",
        "!pip install diffusers\n",
        "!pip install accelerate\n",
        "!pip install compel\n",
        "#!pip install git+https://github.com/huggingface/diffusers\n",
        "#!pip install compel --upgrade\n",
        "!pip install easygoogletranslate\n",
        "\n",
        "from diffusers import AutoPipelineForText2Image, AutoPipelineForImage2Image, AutoPipelineForInpainting\n",
        "from diffusers import (\n",
        "    DDPMScheduler,\n",
        "    DDIMScheduler,\n",
        "    PNDMScheduler,\n",
        "    LMSDiscreteScheduler,\n",
        "    EulerAncestralDiscreteScheduler,\n",
        "    EulerDiscreteScheduler,\n",
        "    DPMSolverMultistepScheduler,\n",
        ")\n",
        "from diffusers.utils import make_image_grid, load_image\n",
        "from compel import Compel, ReturnedEmbeddingsType\n",
        "import transformers\n",
        "\n",
        "from easygoogletranslate import EasyGoogleTranslate\n",
        "translator = EasyGoogleTranslate()\n",
        "\n",
        "used_models_array = [\"\"]\n",
        "previous_checkpoint = None\n",
        "previous_lora_path = None\n",
        "pipe = None\n",
        "previous_mode = None\n",
        "downloaded_model_name = None\n",
        "downloaded_model_basename = None\n",
        "downloaded_lora_name = None\n",
        "downloaded_lora_basename = None\n",
        "current_url = None\n",
        "previous_url = None\n",
        "lora_url = None\n",
        "previous_lora_url = None\n",
        "civitai_models = []\n",
        "previous_clip_skip = 1\n",
        "\n",
        "clear_output()\n",
        "print(\"Установка завершена :)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkHQj8AHJKzr"
      },
      "outputs": [],
      "source": [
        "# @title Подготовка Stable Diffusion: { vertical-output: true, form-width: \"10%\", display-mode: \"form\" }\n",
        "# @markdown\n",
        "# @markdown Модели для загрузки в скрипт:\n",
        "# @markdown\n",
        "# @markdown [CivitAI](https://civitai.com/models)\n",
        "# @markdown\n",
        "# @markdown [HuggingFace](https://huggingface.co/models?library=diffusers)\n",
        "\n",
        "#!nvidia-smi\n",
        "\n",
        "####################\n",
        "# Список опробованных мною моделей:\n",
        "# PicX_real:       GraydientPlatformAPI/picx-real\n",
        "# Juggernaut:      digiplay/Juggernaut_final\n",
        "# Juggernaut XL:   frankjoshua/juggernautXL_version6Rundiffusion\n",
        "# RealVisXL 3.0:   SG161222/RealVisXL_V3.0_Turbo\n",
        "# Base 1.5:        runwayml/stable-diffusion-v1-5\n",
        "# Base SDXL:       stabilityai/stable-diffusion-xl-base-1.0\n",
        "# Base SDXL Turbo: stabilityai/sdxl-turbo\n",
        "####################\n",
        "\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown Ваш токен с сайта CivitAI (опционально, для скачивания моделей с CivitAI, которые требуют регистрацию на сайте.\n",
        "# @markdown\n",
        "# @markdown Взять его можно в настройках вашего аккаунта CivitAI, в блоке API Keys):\n",
        "civitai_token = \"\" # @param {type:\"string\"}\n",
        "# @markdown Модель для загрузки:\n",
        "current_checkpoint = \"\" # @param [\"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-xl-base-1.0\", \"runwayml/stable-diffusion-inpainting\", \"stabilityai/sdxl-turbo\", \"digiplay/Juggernaut_final\", \"GraydientPlatformAPI/picx-real\", \"frankjoshua/juggernautXL_version6Rundiffusion\", \"SG161222/RealVisXL_V3.0_Turbo\", \"SG161222/Realistic_Vision_V6.0_B1_noVAE\", \"stablediffusionapi/lob-realvisxl-v20\"] {allow-input: true}\n",
        "# @markdown Использовать safetensors?\n",
        "use_safetensors = True # @param [\"True\", \"False\", \"None\"] {type:\"raw\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown Использовать LoRA?\n",
        "use_lora = False # @param {type:\"boolean\"}\n",
        "# @markdown Текущая LoRA:\n",
        "# @markdown ---\n",
        "# @markdown Для скачивания с HuggingFace:\n",
        "lora_path = \"\" # @param [\"nerijs/pixel-art-xl\", \"ntc-ai/SDXL-LoRA-slider.cinematic-lighting\"] {allow-input: true}\n",
        "# @markdown Имя файла LoRA:\n",
        "weight_name = \"\" # @param [\"pixel-art-xl.safetensors\", \"cinematic lighting.safetensors\"] {allow-input: true}\n",
        "# @markdown ---\n",
        "# @markdown Ссылка на LoRA для скачивания с сайта CivitAI:\n",
        "lora_url = \"\" # @param {type:\"string\"}\n",
        "# @markdown ---\n",
        "current_device = \"cuda\"\n",
        "# @markdown Пропуск CLIP\n",
        "# @markdown (1 означает что используются все слои, это является значением по умолчанию):\n",
        "clip_skip = 1 # @param {type:\"slider\", min:1, max:12, step:1}\n",
        "## @markdown Вариант:\n",
        "#current_variant = \"fp16\" # @param [\"\", \"fp16\", \"ema\"]\n",
        "\n",
        "display_handle = display(None, display_id=True)\n",
        "\n",
        "def load_civit_model(url):\n",
        "  global current_checkpoint, previous_checkpoint, downloaded_model_name, downloaded_model_basename, previous_url, current_url, civitai_models\n",
        "  for element in civitai_models:\n",
        "    if current_checkpoint in element[0]:\n",
        "      current_checkpoint = element[1]\n",
        "      return\n",
        "\n",
        "  if current_url != previous_url:\n",
        "    if civitai_token:\n",
        "      url = url + \"&token=\" + civitai_token\n",
        "    response = requests.get(url, stream=True)\n",
        "    total_size_in_bytes = int(response.headers.get('content-length', 0))\n",
        "    block_size = 100000\n",
        "    progress_bar = tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True)\n",
        "\n",
        "    if 'content-disposition' in response.headers:\n",
        "      content_disposition = response.headers['content-disposition']\n",
        "      filename_index = content_disposition.find('filename=')\n",
        "      if filename_index != -1:\n",
        "        filename = content_disposition[filename_index + len('filename='):]\n",
        "        filename = unquote(filename)\n",
        "        filename = filename.strip('\"')\n",
        "        downloaded_model_name = filename\n",
        "    if not downloaded_model_name:\n",
        "      downloaded_model_name = os.path.basename(url)\n",
        "\n",
        "    downloaded_model_basename, _ = os.path.splitext(downloaded_model_name)\n",
        "    with open(downloaded_model_name, 'wb') as file:\n",
        "      for data in response.iter_content(block_size):\n",
        "        progress_bar.update(len(data))\n",
        "        file.write(data)\n",
        "    progress_bar.close()\n",
        "    if total_size_in_bytes != 0 and progress_bar.n != total_size_in_bytes:\n",
        "      print(\"Ошибка при скачивании модели :(\")\n",
        "\n",
        "    print(\"\\nМодель \" + downloaded_model_basename + \" успешно загружена :) \")\n",
        "    print(\"Подождите, идёт конвертация модели...\\n\")\n",
        "\n",
        "    from pkg_resources import get_distribution\n",
        "    diffusers_version = get_distribution('diffusers').version\n",
        "    lib_url = \"https://raw.githubusercontent.com/huggingface/diffusers/v\" + diffusers_version + \"/scripts/convert_original_stable_diffusion_to_diffusers.py\"\n",
        "    !wget \"$lib_url\"\n",
        "\n",
        "    !python convert_original_stable_diffusion_to_diffusers.py --checkpoint_path \"$downloaded_model_name\" --dump_path \"$downloaded_model_basename/\" --from_safetensors\n",
        "    previous_url = current_checkpoint\n",
        "    current_checkpoint = downloaded_model_basename\n",
        "    civitai_models.append((url, downloaded_model_basename))\n",
        "    os.remove(downloaded_model_name)\n",
        "    os.remove(\"convert_original_stable_diffusion_to_diffusers.py\")\n",
        "    clear_output()\n",
        "    print(\"Модель \" + downloaded_model_basename + \" успешно сконвертирована и готова к работе :)\")\n",
        "\n",
        "repo_regexp = r'[^\\/\\s]+\\s*\\/\\s*[^\\/\\s]+'\n",
        "link_regexp = r'^https?://\\S+$'\n",
        "\n",
        "if re.match(repo_regexp, current_checkpoint):\n",
        "  current_checkpoint = current_checkpoint\n",
        "elif re.match(link_regexp, current_checkpoint):\n",
        "  current_url = current_checkpoint\n",
        "  load_civit_model(current_checkpoint)\n",
        "else:\n",
        "  print(\"Не удалось найти модель по вашей ссылке. :( Укажите ссылку на репозиторий HuggingFace вида \\\"author/model_name\\\" или прямую ссылку на файл .safetensors с сайта CivitAI\")\n",
        "\n",
        "def flush():\n",
        "  del(pipe)\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "if pipe and not use_lora:\n",
        "  pipe.unload_lora_weights()\n",
        "\n",
        "def run_chkpt(current_checkpoint, lora_path, use_lora, mode):\n",
        "    global previous_checkpoint, previous_lora_path, previous_mode, lora_url, previous_lora_url, downloaded_lora_basename, downloaded_lora_name, pipe, clip_skip, previous_clip_skip\n",
        "    if current_checkpoint != previous_checkpoint or mode != previous_mode or previous_clip_skip != clip_skip:\n",
        "        used_models_array.append(current_checkpoint)\n",
        "        print(\"Устанавливаю модель...\")\n",
        "        if clip_skip > 1:\n",
        "          text_encoder = transformers.CLIPTextModel.from_pretrained(current_checkpoint, subfolder = \"text_encoder\", num_hidden_layers = 12 - (clip_skip - 1), torch_dtype = torch.float16)\n",
        "        if mode == \"txt2img\":\n",
        "          if clip_skip > 1:\n",
        "            pipe = AutoPipelineForText2Image.from_pretrained(current_checkpoint, torch_dtype=torch.float16, use_safetensors=use_safetensors, text_encoder = text_encoder)\n",
        "          else:\n",
        "            pipe = AutoPipelineForText2Image.from_pretrained(current_checkpoint, torch_dtype=torch.float16, use_safetensors=use_safetensors)\n",
        "        if mode == \"img2img\":\n",
        "          if clip_skip > 1:\n",
        "            pipe = AutoPipelineForImage2Image.from_pretrained(current_checkpoint, torch_dtype=torch.float16, use_safetensors=use_safetensors, text_encoder = text_encoder)\n",
        "          else:\n",
        "            pipe = AutoPipelineForImage2Image.from_pretrained(current_checkpoint, torch_dtype=torch.float16, use_safetensors=use_safetensors)\n",
        "        if mode == \"inpainting\":\n",
        "          if clip_skip > 1:\n",
        "            pipe = AutoPipelineForInpainting.from_pretrained(current_checkpoint, torch_dtype=torch.float16, use_safetensors=use_safetensors, text_encoder = text_encoder)\n",
        "          else:\n",
        "            pipe = AutoPipelineForInpainting.from_pretrained(current_checkpoint, torch_dtype=torch.float16, use_safetensors=use_safetensors)\n",
        "        pipe = pipe.to(current_device)\n",
        "        pipe.safety_checker = None\n",
        "        if current_scheduler == \"ddpm\":\n",
        "          pipe.scheduler = ddpm.from_config(pipe.scheduler.config)\n",
        "        if current_scheduler == \"ddim\":\n",
        "          pipe.scheduler = ddim.from_config(pipe.scheduler.config)\n",
        "        if current_scheduler == \"pndm\":\n",
        "          pipe.scheduler = pndm.from_config(pipe.scheduler.config)\n",
        "        if current_scheduler == \"lms\":\n",
        "          pipe.scheduler = lms.from_config(pipe.scheduler.config)\n",
        "        if current_scheduler == \"euler\":\n",
        "          pipe.scheduler = euler.from_config(pipe.scheduler.config)\n",
        "        if current_scheduler == \"euler_anc\":\n",
        "          pipe.scheduler = euler_anc.from_config(pipe.scheduler.config)\n",
        "        if current_scheduler == \"dpm\":\n",
        "          pipe.scheduler = dpm.from_config(pipe.scheduler.config)\n",
        "        print(\"Всё готово к работе :)\")\n",
        "        clear_output()\n",
        "        previous_mode = mode\n",
        "        previous_checkpoint = current_checkpoint\n",
        "        previous_clip_skip = clip_skip\n",
        "    if use_lora:\n",
        "      if lora_path != previous_lora_path and lora_url == \"\":\n",
        "        if pipe:\n",
        "          pipe.unload_lora_weights()\n",
        "        print(\"Устанавливаю LoRA модель...\")\n",
        "        pipe.load_lora_weights(lora_path, weight_name=weight_name)\n",
        "        print(\"Всё готово к работе :)\")\n",
        "        previous_lora_path = lora_path\n",
        "      if lora_url != previous_lora_url and lora_path == \"\" and weight_name == \"\":\n",
        "        if pipe:\n",
        "          pipe.unload_lora_weights()\n",
        "        response = requests.get(lora_url, stream=True)\n",
        "        total_size_in_bytes = int(response.headers.get('content-length', 0))\n",
        "        block_size = 100000\n",
        "        progress_bar = tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True)\n",
        "\n",
        "        if 'content-disposition' in response.headers:\n",
        "          content_disposition = response.headers['content-disposition']\n",
        "          filename_index = content_disposition.find('filename=')\n",
        "          if filename_index != -1:\n",
        "            filename = content_disposition[filename_index + len('filename='):]\n",
        "            filename = unquote(filename)\n",
        "            filename = filename.strip('\"')\n",
        "            downloaded_lora_name = filename\n",
        "        if not downloaded_lora_name:\n",
        "          downloaded_lora_name = os.path.basename(lora_url)\n",
        "\n",
        "        downloaded_lora_basename, _ = os.path.splitext(downloaded_lora_name)\n",
        "        with open(downloaded_lora_name, 'wb') as file:\n",
        "          for data in response.iter_content(block_size):\n",
        "            progress_bar.update(len(data))\n",
        "            file.write(data)\n",
        "        progress_bar.close()\n",
        "        if total_size_in_bytes != 0 and progress_bar.n != total_size_in_bytes:\n",
        "          print(\"Ошибка при скачивании модели :(\")\n",
        "        pipe.load_lora_weights(downloaded_lora_name)\n",
        "        previous_lora_url = lora_url\n",
        "        print(\"Всё готово к работе :)\")\n",
        "\n",
        "\n",
        "# print(\"\\nСписок использованных моделей в течении сессии:\")\n",
        "# model_fields = []\n",
        "# for i, model_name in enumerate(used_models_array, start=1):\n",
        "#     if model_name:\n",
        "#       model_field = widgets.Text(\n",
        "#           value=model_name,\n",
        "#           description=f'Модель {i-1}:',\n",
        "#           disabled=False,\n",
        "#           layout=widgets.Layout(width=\"auto\")\n",
        "#       )\n",
        "#       model_fields.append(model_field)\n",
        "\n",
        "# display(widgets.VBox(model_fields))\n",
        "\n",
        "# if len(used_models_array) == 1:\n",
        "#   print(\"Пока что список моделей пуст :(\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Настройка параметров генерации: { form-width: \"10%\", display-mode: \"form\" }\n",
        "# Здесь указываем переменные для пайплайна Stable Diffusion\n",
        "# Дефолтный промпт для лучшего качества: (8k, ultra realistic, highly detailed, cinematic lighting)\n",
        "\n",
        "# @markdown Язык промпта и негативного промпта:\n",
        "language = \"English\" # @param [\"English\", \"Русский\", \"Автоопределение\"]\n",
        "# @markdown Промпт:\n",
        "prompt = \"young woman, blonde, blue eyes\" # @param {type:\"string\"}\n",
        "# @markdown Негативный промпт:\n",
        "negs = \"\" # @param {type:\"string\"}\n",
        "if language == \"Русский\":\n",
        "  prompt = translator.translate(prompt, source_language='ru', target_language='en')\n",
        "  negs = translator.translate(negs, source_language='ru', target_language='en')\n",
        "elif language == \"Автоопределение\":\n",
        "  prompt = translator.translate(prompt, target_language='en')\n",
        "  negs = translator.translate(negs, target_language='en')\n",
        "else:\n",
        "  prompt = prompt\n",
        "  negs = negs\n",
        "\n",
        "# @markdown Стиль генерируемого изображения:\n",
        "styles = \"Без стиля\" # @param [\"Без стиля\", \"ran4erep's style\", \"3D модель\", \"Аналоговая плёнка\", \"Аниме\", \"Кинематографичный\", \"Комикс\", \"Пластилин\", \"Цифровой арт\", \"Фентези\", \"Изометрический\", \"Набросок\", \"Лоу-поли\", \"Неонпанк\", \"Оригами\", \"Фотография\", \"Пиксель-арт\", \"Текстура\", \"Абстракция\", \"Абстрактный экспрессионизм\", \"Гиперреализм\", \"Поп-арт\", \"Ренесанс\", \"Стимпанк\", \"Сюрреализм\", \"Футуризм\", \"Синтвейв-футуризм\", \"Ретро-футуризм\", \"Сай-фай\", \"Вапорвейв-футуризм\", \"Антиутопический\", \"Готический\", \"Гранж\", \"Хоррор\", \"Лавкрафтовский\", \"Жуткий\", \"Минимализм\", \"Нуар\", \"Длинная выдержка\", \"Tilt-Shift\", \"Фото со смартфона\"]\n",
        "# @markdown ---\n",
        "\n",
        "def latents_to_rgb(latents):\n",
        "    weights = (\n",
        "        (60, -60, 25, -70),\n",
        "        (60,  -5, 15, -50),\n",
        "        (60,  10, -5, -35)\n",
        "    )\n",
        "\n",
        "    weights_tensor = torch.t(torch.tensor(weights, dtype=latents.dtype).to(latents.device))\n",
        "    biases_tensor = torch.tensor((150, 140, 130), dtype=latents.dtype).to(latents.device)\n",
        "    rgb_tensor = torch.einsum(\"...lxy,lr -> ...rxy\", latents, weights_tensor) + biases_tensor.unsqueeze(-1).unsqueeze(-1)\n",
        "    image_array = rgb_tensor.clamp(0, 255)[0].byte().cpu().numpy()\n",
        "    image_array = image_array.transpose(1, 2, 0)  # Change the order of dimensions\n",
        "\n",
        "    return Image.fromarray(image_array)\n",
        "\n",
        "def decode_tensors(pipe, step, timestep, callback_kwargs):\n",
        "  if step % 5 == 0:\n",
        "    latents = callback_kwargs[\"latents\"]\n",
        "\n",
        "    image = latents_to_rgb(latents)\n",
        "    image_resized = image.resize((412, 412), Image.NEAREST)\n",
        "    update_display(image_resized, display_id=display_handle.display_id)\n",
        "\n",
        "  return callback_kwargs\n",
        "\n",
        "if styles != \"Без стиля\":\n",
        "  if styles == \"ran4erep's style\":\n",
        "    prompt = prompt + \", 8k, ultra realistic, highly detailed\"\n",
        "    negs = negs + \", canvas frame, cartoon, 3d, disfigured, bad art, deformed, extra limbs, close up, b&w, wierd colors, blurry, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, ugly, blurry, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, out of frame, ugly, extra limbs, bad anatomy, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, mutated hands, fused fingers, too many fingers, long neck, Photoshop, video game, ugly, tiling, poorly drawn hands, poorly drawn feet, poorly drawn face, out of frame, mutation, mutated, extra limbs, extra legs, extra arms, disfigured, deformed, cross-eye, body out of frame, blurry, bad art, bad anatomy, 3d render\"\n",
        "  if styles == \"3D модель\":\n",
        "    prompt = \"professional 3d model {\" + prompt + \"} . octane render, highly detailed, volumetric, dramatic lighting\"\n",
        "    negs   = negs + \", ugly, deformed, noisy, low poly, blurry, painting\"\n",
        "  if styles == \"Аналоговая плёнка\":\n",
        "    prompt = \"analog film photo {\" + prompt + \"} . faded film, desaturated, 35mm photo, grainy, vignette, vintage, Kodachrome, Lomography, stained, highly detailed, found footage\"\n",
        "    negs   = negs + \", painting, drawing, illustration, glitch, deformed, mutated, cross-eyed, ugly, disfigured\"\n",
        "  if styles == \"Аниме\":\n",
        "    prompt = \"anime artwork {\" + prompt + \"} . anime style, key visual, vibrant, studio anime, highly detailed\"\n",
        "    negs   = negs + \", photo, deformed, black and white, realism, disfigured, low contrast\"\n",
        "  if styles == \"Кинематографичный\":\n",
        "    prompt = \"cinematic film still {\" + prompt + \"} . shallow depth of field, vignette, highly detailed, high budget, bokeh, cinemascope, moody, epic, gorgeous, film grain, grainy\"\n",
        "    negs   = negs + \", anime, cartoon, graphic, text, painting, crayon, graphite, abstract, glitch, deformed, mutated, ugly, disfigured\"\n",
        "  if styles == \"Комикс\":\n",
        "    prompt = \"comic {\" + prompt + \"} . graphic illustration, comic art, graphic novel art, vibrant, highly detailed\"\n",
        "    negs   = negs + \", photograph, deformed, glitch, noisy, realistic, stock photo\"\n",
        "  if styles == \"Пластилин\":\n",
        "    prompt = \"play-doh style {\" + prompt + \"} . sculpture, clay art, centered composition, Claymation\"\n",
        "    negs   = negs + \", sloppy, messy, grainy, highly detailed, ultra textured, photo\"\n",
        "  if styles == \"Цифровой арт\":\n",
        "    prompt = \"concept art {\" + prompt + \"} . digital artwork, illustrative, painterly, matte painting, highly detailed\"\n",
        "    negs   = negs + \", photo, photorealistic, realism, ugly\"\n",
        "  if styles == \"Фентези\":\n",
        "    prompt = \"ethereal fantasy concept art of {\" + prompt + \"} . magnificent, celestial, ethereal, painterly, epic, majestic, magical, fantasy art, cover art, dreamy\"\n",
        "    negs   = negs + \", photographic, realistic, realism, 35mm film, dslr, cropped, frame, text, deformed, glitch, noise, noisy, off-center, deformed, cross-eyed, closed eyes, bad anatomy, ugly, disfigured, sloppy, duplicate, mutated, black and white\"\n",
        "  if styles == \"Изометрический\":\n",
        "    prompt = \"isometric style {\" + prompt + \"} . vibrant, beautiful, crisp, detailed, ultra detailed, intricate\"\n",
        "    negs   = negs + \", deformed, mutated, ugly, disfigured, blur, blurry, noise, noisy, realistic, photographic\"\n",
        "  if styles == \"Набросок\":\n",
        "    prompt = \"line art drawing {\" + prompt + \"} . professional, sleek, modern, minimalist, graphic, line art, vector graphics\"\n",
        "    negs   = negs + \", anime, photorealistic, 35mm film, deformed, glitch, blurry, noisy, off-center, deformed, cross-eyed, closed eyes, bad anatomy, ugly, disfigured, mutated, realism, realistic, impressionism, expressionism, oil, acrylic\"\n",
        "  if styles == \"Лоу-поли\":\n",
        "    prompt = \"low-poly style {\" + prompt + \"} . low-poly game art, polygon mesh, jagged, blocky, wireframe edges, centered composition\"\n",
        "    negs   = negs + \", noisy, sloppy, messy, grainy, highly detailed, ultra textured, photo\"\n",
        "  if styles == \"Неонпанк\":\n",
        "    prompt = \"neonpunk style {\" + prompt + \"} . cyberpunk, vaporwave, neon, vibes, vibrant, stunningly beautiful, crisp, detailed, sleek, ultramodern, magenta highlights, dark purple shadows, high contrast, cinematic, ultra detailed, intricate, professional\"\n",
        "    negs   = negs + \", painting, drawing, illustration, glitch, deformed, mutated, cross-eyed, ugly, disfigured\"\n",
        "  if styles == \"Оригами\":\n",
        "    prompt = \"origami style {\" + prompt + \"} . paper art, pleated paper, folded, origami art, pleats, cut and fold, centered composition\"\n",
        "    negs   = negs + \", noisy, sloppy, messy, grainy, highly detailed, ultra textured, photo\"\n",
        "  if styles == \"Фотография\":\n",
        "    prompt = \"cinematic photo {\" + prompt + \"} . 35mm photograph, film, bokeh, professional, 4k, highly detailed\"\n",
        "    negs   = negs + \", drawing, painting, crayon, sketch, graphite, impressionist, noisy, blurry, soft, deformed, ugly\"\n",
        "  if styles == \"Пиксель-арт\":\n",
        "    prompt = \"pixel-art {\" + prompt + \"} . low-res, blocky, pixel art style, 8-bit graphics\"\n",
        "    negs   = negs + \", sloppy, messy, blurry, noisy, highly detailed, ultra textured, photo, realistic\"\n",
        "  if styles == \"Текстура\":\n",
        "    prompt = \"texture {\" + prompt + \"} top down close-up\"\n",
        "    negs   = negs + \", ugly, deformed, noisy, blurry\"\n",
        "  if styles == \"Абстракция\":\n",
        "    prompt = \"abstract style {\" + prompt + \"} . non-representational, colors and shapes, expression of feelings, imaginative, highly detailed\"\n",
        "    negs   = negs + \", realistic, photographic, figurative, concrete\"\n",
        "  if styles == \"Абстрактный экспрессионизм\":\n",
        "    prompt = \"abstract expressionist painting {\" + prompt + \"} . energetic brushwork, bold colors, abstract forms, expressive, emotional\"\n",
        "    negs   = negs + \", realistic, photorealistic, low contrast, plain, simple, monochrome\"\n",
        "  if styles == \"Гиперреализм\":\n",
        "    prompt = \"hyperrealistic art {\" + prompt + \"} . extremely high-resolution details, photographic, realism pushed to extreme, fine texture, incredibly lifelike\"\n",
        "    negs   = negs + \", simplified, abstract, unrealistic, impressionistic, low resolution\"\n",
        "  if styles == \"Поп-арт\":\n",
        "    prompt = \"pop Art style {\" + prompt + \"} . bright colors, bold outlines, popular culture themes, ironic or kitsch\"\n",
        "    negs   = negs + \", ugly, deformed, noisy, blurry, low contrast, realism, photorealistic, minimalist\"\n",
        "  if styles == \"Ренесанс\":\n",
        "    prompt = \"renaissance style {\" + prompt + \"} . realistic, perspective, light and shadow, religious or mythological themes, highly detailed\"\n",
        "    negs   = negs + \", ugly, deformed, noisy, blurry, low contrast, modernist, minimalist, abstract\"\n",
        "  if styles == \"Стимпанк\":\n",
        "    prompt = \"steampunk style {\" + prompt + \"} . antique, mechanical, brass and copper tones, gears, intricate, detailed\"\n",
        "    negs   = negs + \", deformed, glitch, noisy, low contrast, anime, photorealistic\"\n",
        "  if styles == \"Сюрреализм\":\n",
        "    prompt = \"surrealist art {\" + prompt + \"} . dreamlike, mysterious, provocative, symbolic, intricate, detailed\"\n",
        "    negs   = negs + \", anime, photorealistic, realistic, deformed, glitch, noisy, low contrast\"\n",
        "  if styles == \"Футуризм\":\n",
        "    prompt = \"futuristic style {\" + prompt + \"} . sleek, modern, ultramodern, high tech, detailed\"\n",
        "    negs   = negs + \", ugly, deformed, noisy, blurry, low contrast, realism, photorealistic, vintage, antique\"\n",
        "  if styles == \"Синтвейв-футуризм\":\n",
        "    prompt = \"retro cyberpunk {\" + prompt + \"} . 80’s inspired, synthwave, neon, vibrant, detailed, retro futurism\"\n",
        "    negs   = negs + \", modern, desaturated, black and white, realism, low contrast\"\n",
        "  if styles == \"Ретро-футуризм\":\n",
        "    prompt = \"retro-futuristic {\" + prompt + \"} . vintage sci-fi, 50s and 60s style, atomic age, vibrant, highly detailed\"\n",
        "    negs   = negs + \", contemporary, realistic, rustic, primitive\"\n",
        "  if styles == \"Сай-фай\":\n",
        "    prompt = \"sci-fi style {\" + prompt + \"} . futuristic, technological, alien worlds, space themes, advanced civilizations\"\n",
        "    negs   = negs + \", ugly, deformed, noisy, blurry, low contrast, realism, photorealistic, historical, medieval\"\n",
        "  if styles == \"Вапорвейв-футуризм\":\n",
        "    prompt = \"vaporwave style {\" + prompt + \"} . retro aesthetic, cyberpunk, vibrant, neon colors, vintage 80s and 90s style, highly detailed\"\n",
        "    negs   = negs + \", monochrome, muted colors, realism, rustic, minimalist, dark\"\n",
        "  if styles == \"Антиутопический\":\n",
        "    prompt = \"dystopian style {\" + prompt + \"} . bleak, post-apocalyptic, somber, dramatic, highly detailed\"\n",
        "    negs   = negs + \", ugly, deformed, noisy, blurry, low contrast, cheerful, optimistic, vibrant, colorful\"\n",
        "  if styles == \"Готический\":\n",
        "    prompt = \"gothic style {\" + prompt + \"} . dark, mysterious, haunting, dramatic, ornate, detailed\"\n",
        "    negs   = negs + \", ugly, deformed, noisy, blurry, low contrast, realism, photorealistic, cheerful, optimistic\"\n",
        "  if styles == \"Гранж\":\n",
        "    prompt = \"grunge style {\" + prompt + \"} . textured, distressed, vintage, edgy, punk rock vibe, dirty, noisy\"\n",
        "    negs   = negs + \", smooth, clean, minimalist, sleek, modern, photorealistic\"\n",
        "  if styles == \"Хоррор\":\n",
        "    prompt = \"horror-themed {\" + prompt + \"} . eerie, unsettling, dark, spooky, suspenseful, grim, highly detailed\"\n",
        "    negs   = negs + \", cheerful, bright, vibrant, light-hearted, cute\"\n",
        "  if styles == \"Лавкрафтовский\":\n",
        "    prompt = \"lovecraftian horror {\" + prompt + \"} . eldritch, cosmic horror, unknown, mysterious, surreal, highly detailed\"\n",
        "    negs   = negs + \", light-hearted, mundane, familiar, simplistic, realistic\"\n",
        "  if styles == \"Жуткий\":\n",
        "    prompt = \"macabre style {\" + prompt + \"} . dark, gothic, grim, haunting, highly detailed\"\n",
        "    negs   = negs + \", bright, cheerful, light-hearted, cartoonish, cute\"\n",
        "  if styles == \"Минимализм\":\n",
        "    prompt = \"minimalist style {\" + prompt + \"} . simple, clean, uncluttered, modern, elegant\"\n",
        "    negs   = negs + \", ornate, complicated, highly detailed, cluttered, disordered, messy, noisy\"\n",
        "  if styles == \"Нуар\":\n",
        "    prompt = \"film noir style {\" + prompt + \"} . monochrome, high contrast, dramatic shadows, 1940s style, mysterious, cinematic\"\n",
        "    negs   = negs + \", ugly, deformed, noisy, blurry, low contrast, realism, photorealistic, vibrant, colorful\"\n",
        "  if styles == \"Длинная выдержка\":\n",
        "    prompt = \"long exposure photo of {\" + prompt + \"} . Blurred motion, streaks of light, surreal, dreamy, ghosting effect, highly detailed\"\n",
        "    negs   = negs + \", static, noisy, deformed, shaky, abrupt, flat, low contrast\"\n",
        "  if styles == \"Tilt-Shift\":\n",
        "    prompt = \"tilt-shift photo of {\" + prompt + \"} . selective focus, miniature effect, blurred background, highly detailed, vibrant, perspective control\"\n",
        "    negs   = negs + \", blurry, noisy, deformed, flat, low contrast, unrealistic, oversaturated, underexposed\"\n",
        "  if styles == \"Фото со смартфона\":\n",
        "    prompt = \"iphone photo {\" + prompt + \"} . large depth of field, deep depth of field, highly detailed\"\n",
        "    negs   = negs + \", drawing, painting, crayon, sketch, graphite, impressionist, noisy, blurry, soft, deformed, ugly, shallow depth of field, bokeh\"\n",
        "# @markdown Для какой версии Stable Diffusion вы загрузили модель? (Это важно для работоспособности веса токенов, иначе будет ошибка)\n",
        "sd_type = \"Stable Diffusion 1.5/2.0\" # @param [\"Stable Diffusion 1.5/2.0\", \"Stable Diffusion XL (Turbo)\"]\n",
        "# @markdown Вес для SD 1.5 записывается как + или - после слова внутри токена: \"cat playing with ball+++++\", \"cat+ playing with ball\"\n",
        "# @markdown\n",
        "# @markdown Вес для SDXL записывается как дробное число после скобок, внутри которых есть слово или даже целый токен: \"cat (playing with ball)1.5\"\n",
        "# @markdown\n",
        "# @markdown ---\n",
        "# @markdown Ширина:\n",
        "width = 512 # @param {type:\"number\"}\n",
        "# @markdown Высота:\n",
        "height = 512 # @param {type:\"number\"}\n",
        "# @markdown Количество изображений:\n",
        "images_count = 1 # @param {type:\"slider\", min:1, max:10, step:1}\n",
        "# @markdown Шаги:\n",
        "steps = 20 # @param {type:\"number\"}\n",
        "# @markdown Шкала инструкции:\n",
        "gscale = 5 # @param {type:\"number\"}\n",
        "# @markdown Текущий планировщик:\n",
        "current_scheduler = \"euler\" # @param [\"ddpm\", \"ddim\", \"pndm\", \"lms\", \"euler_anc\", \"euler\", \"dpm\"] {type:\"string\"}\n",
        "\n",
        "if pipe in globals() or pipe is not None:\n",
        "  if current_scheduler == \"ddpm\":\n",
        "    pipe.scheduler = ddpm.from_config(pipe.scheduler.config)\n",
        "  if current_scheduler == \"ddim\":\n",
        "    pipe.scheduler = ddim.from_config(pipe.scheduler.config)\n",
        "  if current_scheduler == \"pndm\":\n",
        "    pipe.scheduler = pndm.from_config(pipe.scheduler.config)\n",
        "  if current_scheduler == \"lms\":\n",
        "    pipe.scheduler = lms.from_config(pipe.scheduler.config)\n",
        "  if current_scheduler == \"euler\":\n",
        "    pipe.scheduler = euler.from_config(pipe.scheduler.config)\n",
        "  if current_scheduler == \"euler_anc\":\n",
        "    pipe.scheduler = euler_anc.from_config(pipe.scheduler.config)\n",
        "  if current_scheduler == \"dpm\":\n",
        "    pipe.scheduler = dpm.from_config(pipe.scheduler.config)\n",
        "\n",
        "# @markdown Использовать случайный seed?\n",
        "randomness = True # @param {type:\"boolean\"}\n",
        "# @markdown Seed:\n",
        "seed = None # @param {type:\"integer\"}"
      ],
      "metadata": {
        "id": "WVG80_y8vCpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Работа Stable Diffusion\n",
        "Не запускайте этот блок кода целиком. Разверните его и вы увидите различные режимы работы Stable Diffusion. Запустите нужный вам режим."
      ],
      "metadata": {
        "id": "Vq2nSTBmoWq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Text2Image (Генерация изображения из текста): { form-width: \"10%\", display-mode: \"form\" }\n",
        "# @markdown\n",
        "# @markdown <-- Начать генерацию\n",
        "# Генерация картинки\n",
        "# @markdown\n",
        "# @markdown Показывать диффузию в реальном времени?\n",
        "show_diffusion = True # @param {type:\"boolean\"}\n",
        "\n",
        "ddpm = DDPMScheduler.from_pretrained(current_checkpoint, subfolder=\"scheduler\")\n",
        "ddim = DDIMScheduler.from_pretrained(current_checkpoint, subfolder=\"scheduler\")\n",
        "pndm = PNDMScheduler.from_pretrained(current_checkpoint, subfolder=\"scheduler\")\n",
        "lms = LMSDiscreteScheduler.from_pretrained(current_checkpoint, subfolder=\"scheduler\")\n",
        "euler_anc = EulerAncestralDiscreteScheduler.from_pretrained(current_checkpoint, subfolder=\"scheduler\")\n",
        "euler = EulerDiscreteScheduler.from_pretrained(current_checkpoint, subfolder=\"scheduler\")\n",
        "dpm = DPMSolverMultistepScheduler.from_pretrained(current_checkpoint, subfolder=\"scheduler\")\n",
        "\n",
        "run_chkpt(current_checkpoint, lora_path, use_lora, \"txt2img\")\n",
        "\n",
        "if sd_type == \"Stable Diffusion 1.5/2.0\":\n",
        "  compel_proc = Compel(tokenizer=pipe.tokenizer, text_encoder=pipe.text_encoder)\n",
        "  prompt_embeds = compel_proc(prompt)\n",
        "\n",
        "if sd_type == \"Stable Diffusion XL (Turbo)\":\n",
        "  compel = Compel(\n",
        "    tokenizer=[pipe.tokenizer, pipe.tokenizer_2] ,\n",
        "    text_encoder=[pipe.text_encoder, pipe.text_encoder_2],\n",
        "    returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
        "    requires_pooled=[False, True]\n",
        "  )\n",
        "  conditioning, pooled = compel(prompt)\n",
        "\n",
        "#####################################################################\n",
        "# Информация о текущей генерации\n",
        "prompt_display = '\\n'.join([prompt[i:i+60] for i in range(0, len(prompt), 60)])\n",
        "negs_display = '\\n'.join([negs[i:i+60] for i in range(0, len(negs), 60)])\n",
        "\n",
        "output = [\n",
        "    \"# Текущая модель Stable Diffusion: \" + current_checkpoint,\n",
        "]\n",
        "if use_lora:\n",
        "    if lora_url == \"\" and lora_path and weight_name:\n",
        "      output.append(\"# Текущая модель LoRA: \" + lora_path)\n",
        "    elif lora_url and lora_path == \"\" and weight_name == \"\":\n",
        "      output.append(\"# Текущая модель LoRA: \" + downloaded_lora_basename)\n",
        "output.extend([\n",
        "    \"# Текущий стиль: \" + styles,\n",
        "    \"# Промпт: \" + prompt_display,\n",
        "    \"# Негативный промпт: \" + negs_display,\n",
        "    \"# Разрешение: \" + str(width) + \"x\" + str(height),\n",
        "    \"# Количество генерируемых изображений: \" + str(images_count)\n",
        "])\n",
        "#max_length_string = max(len(s.replace('\\n', '')) for s in output)\n",
        "max_length_string = 70\n",
        "\n",
        "print(\"#\" * max_length_string )\n",
        "for item in output:\n",
        "  print(item)\n",
        "\n",
        "######################################################################\n",
        "if not randomness:\n",
        "  generator = torch.Generator(current_device).manual_seed(seed)\n",
        "  print(\"# Seed этой генерации: \" + str(seed) + \"\\n\" + (\"#\" * max_length_string) )\n",
        "elif randomness:\n",
        "  current_seed = torch.Generator(current_device).seed()\n",
        "  generator = torch.Generator(current_device).manual_seed(current_seed)\n",
        "  print(\"# Seed этой генерации: \" + str(current_seed) + \"\\n\" + (\"#\" * max_length_string ))\n",
        "\n",
        "\n",
        "#result = pipe(prompt=prompt, height=height, width=width, num_inference_steps=steps, guidance_scale=gscale, negative_prompt=negs, generator=generator, num_images_per_prompt=images_count)\n",
        "\n",
        "if sd_type == \"Stable Diffusion 1.5/2.0\":\n",
        "  if show_diffusion:\n",
        "    torch.cuda.empty_cache()\n",
        "    result = pipe(prompt_embeds=prompt_embeds, callback_on_step_end=decode_tensors, callback_on_step_end_tensor_inputs=[\"latents\"], height=height, width=width, num_inference_steps=steps, guidance_scale=gscale, negative_prompt=negs, generator=generator, num_images_per_prompt=images_count)\n",
        "  else:\n",
        "    torch.cuda.empty_cache()\n",
        "    result = pipe(prompt_embeds=prompt_embeds, height=height, width=width, num_inference_steps=steps, guidance_scale=gscale, negative_prompt=negs, generator=generator, num_images_per_prompt=images_count)\n",
        "\n",
        "if sd_type == \"Stable Diffusion XL (Turbo)\":\n",
        "  if show_diffusion:\n",
        "    torch.cuda.empty_cache()\n",
        "    result = pipe(prompt_embeds=conditioning, pooled_prompt_embeds=pooled, callback_on_step_end=decode_tensors, callback_on_step_end_tensor_inputs=[\"latents\"], height=height, width=width, num_inference_steps=steps, guidance_scale=gscale, negative_prompt=negs, generator=generator, num_images_per_prompt=images_count)\n",
        "  else:\n",
        "    torch.cuda.empty_cache()\n",
        "    result = pipe(prompt_embeds=conditioning, pooled_prompt_embeds=pooled, height=height, width=width, num_inference_steps=steps, guidance_scale=gscale, negative_prompt=negs, generator=generator, num_images_per_prompt=images_count)\n",
        "\n",
        "# Вывод и сохрарнение результата\n",
        "\n",
        "if use_gdrive:\n",
        "  today = str(date.today())\n",
        "  if not os.path.exists(\"/content/gdrive/MyDrive/SDOutput/\" + today):\n",
        "    os.makedirs(\"/content/gdrive/MyDrive/SDOutput/\" + today, exist_ok=True)\n",
        "  for i in range(images_count):\n",
        "    time = datetime.now()\n",
        "    time = str(time.strftime(\"%H-%M-%S\"))\n",
        "    file_name = time + \"_\" + \"seed_\" + str(current_seed) + \"_image\" + str(i) +\".png\"\n",
        "    file_name = \"/content/gdrive/MyDrive/SDOutput/\" + today + \"/\" + file_name\n",
        "    images = make_image_grid(result.images, rows=1, cols=images_count)\n",
        "    result.images[i].save(file_name)\n",
        "    print(\"Сохранено: \" + file_name)\n",
        "\n",
        "clear_output()\n",
        "#update_display(result, display_id=display_handle.display_id)\n",
        "print(\"#\" * max_length_string )\n",
        "print(\"# Текущая модель Stable Diffusion: \" + current_checkpoint)\n",
        "if use_lora:\n",
        "  if lora_url == \"\" and lora_path and weight_name:\n",
        "    output.append(\"# Текущая модель LoRA: \" + lora_path)\n",
        "  elif lora_url and lora_path == \"\" and weight_name == \"\":\n",
        "    output.append(\"# Текущая модель LoRA: \" + downloaded_lora_basename)\n",
        "print(\"# Текущий стиль: \" + styles)\n",
        "print(\"# Промпт: \" + prompt_display)\n",
        "print(\"# Негативный промпт: \" + negs_display)\n",
        "print(\"# Разрешение: \" + str(width) + \"x\" + str(height))\n",
        "print(\"# Количество генерируемых изображений: \" + str(images_count))\n",
        "if not randomness:\n",
        "  print(\"# Seed этой генерации: \" + str(seed) + \"\\n\" + (\"#\" * max_length_string ))\n",
        "elif randomness:\n",
        "  print(\"# Seed этой генерации: \" + str(current_seed) + \"\\n\" + (\"#\" * max_length_string ))\n",
        "make_image_grid(result.images, rows=1, cols=images_count)"
      ],
      "metadata": {
        "id": "Nl8kcwyOqfd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Загрузка изображения для модуля Image2Image\n",
        "print(\"Выберите исходное изображение: \")\n",
        "init_image = files.upload()\n",
        "image_key = list(init_image.keys())[0]\n",
        "image_data = init_image[image_key]\n",
        "img = Image.open(io.BytesIO(image_data))\n",
        "img_width, img_height = img.size"
      ],
      "metadata": {
        "cellView": "form",
        "id": "FtAIUUMVO8hS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Image2Image (Генерация изображения из другого изображения): { form-width: \"10%\", display-mode: \"form\" }\n",
        "# @markdown <-- Начать генерацию\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown Сила:\n",
        "\n",
        "# @markdown Чем ниже значене, тем ближе генерация будет к изображению, которое вы загрузили. Чем больше значение, тем сильнее нейросеть будет креативничать.\n",
        "\n",
        "img2img_strength = 0.3 # @param {type:\"slider\", min:0.1, max:1.0, step:0.1}\n",
        "\n",
        "# @markdown Силу нужно комбинировать с шагами. Итоговое количество шагов для генерации шума рассчитывается по формуле (Шаги * Сила).\n",
        "\n",
        "# @markdown Шаги:\n",
        "steps = 25 # @param {type:\"number\"}\n",
        "# @markdown ---\n",
        "# @markdown Показывать диффузию в реальном времени?\n",
        "show_diffusion = True # @param {type:\"boolean\"}\n",
        "# @markdown ---\n",
        "\n",
        "ddpm = DDPMScheduler.from_pretrained(current_checkpoint, subfolder=\"scheduler\")\n",
        "ddim = DDIMScheduler.from_pretrained(current_checkpoint, subfolder=\"scheduler\")\n",
        "pndm = PNDMScheduler.from_pretrained(current_checkpoint, subfolder=\"scheduler\")\n",
        "lms = LMSDiscreteScheduler.from_pretrained(current_checkpoint, subfolder=\"scheduler\")\n",
        "euler_anc = EulerAncestralDiscreteScheduler.from_pretrained(current_checkpoint, subfolder=\"scheduler\")\n",
        "euler = EulerDiscreteScheduler.from_pretrained(current_checkpoint, subfolder=\"scheduler\")\n",
        "dpm = DPMSolverMultistepScheduler.from_pretrained(current_checkpoint, subfolder=\"scheduler\")\n",
        "\n",
        "run_chkpt(current_checkpoint, lora_path, use_lora, \"img2img\")\n",
        "\n",
        "\n",
        "if init_image:\n",
        "\n",
        "  if sd_type == \"Stable Diffusion 1.5/2.0\":\n",
        "    compel_proc = Compel(tokenizer=pipe.tokenizer, text_encoder=pipe.text_encoder)\n",
        "    prompt_embeds = compel_proc(prompt)\n",
        "\n",
        "  if sd_type == \"Stable Diffusion XL (Turbo)\":\n",
        "    compel = Compel(\n",
        "      tokenizer=[pipe.tokenizer, pipe.tokenizer_2] ,\n",
        "      text_encoder=[pipe.text_encoder, pipe.text_encoder_2],\n",
        "      returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
        "      requires_pooled=[False, True]\n",
        "    )\n",
        "    conditioning, pooled = compel(prompt)\n",
        "  prompt_display = '\\n'.join([prompt[i:i+60] for i in range(0, len(prompt), 60)])\n",
        "  negs_display = '\\n'.join([negs[i:i+60] for i in range(0, len(negs), 60)])\n",
        "  output = [\n",
        "      \"# Текущая модель Stable Diffusion: \" + current_checkpoint,\n",
        "  ]\n",
        "  if lora_url == \"\" and lora_path and weight_name:\n",
        "    output.append(\"# Текущая модель LoRA: \" + lora_path)\n",
        "  elif lora_url and lora_path == \"\" and weight_name == \"\":\n",
        "    output.append(\"# Текущая модель LoRA: \" + downloaded_lora_basename)\n",
        "  output.extend([\n",
        "      \"# Текущий стиль: \" + styles,\n",
        "      \"# Промпт: \" + prompt_display,\n",
        "      \"# Негативный промпт: \" + negs_display,\n",
        "      \"# Разрешение: \" + str(img_width) + \"x\" + str(img_height),\n",
        "      \"# Сила: \" + str(img2img_strength)\n",
        "  ])\n",
        "  max_length_string = 70\n",
        "\n",
        "  print(\"#\" * max_length_string )\n",
        "  for item in output:\n",
        "    print(item)\n",
        "\n",
        "  if not randomness:\n",
        "    generator = torch.Generator(current_device).manual_seed(seed)\n",
        "    print(\"# Seed этой генерации: \" + str(seed) + \"\\n\" + (\"#\" * max_length_string) )\n",
        "  elif randomness:\n",
        "    current_seed = torch.Generator(current_device).seed()\n",
        "    generator = torch.Generator(current_device).manual_seed(current_seed)\n",
        "    print(\"# Seed этой генерации: \" + str(current_seed) + \"\\n\" + (\"#\" * max_length_string ))\n",
        "\n",
        "  if sd_type == \"Stable Diffusion 1.5/2.0\":\n",
        "    if show_diffusion:\n",
        "      torch.cuda.empty_cache()\n",
        "      result = pipe(prompt_embeds=prompt_embeds, callback_on_step_end=decode_tensors, callback_on_step_end_tensor_inputs=[\"latents\"], image=img, strength = img2img_strength, num_inference_steps=steps, guidance_scale=gscale, negative_prompt=negs, generator=generator).images[0]\n",
        "    else:\n",
        "      torch.cuda.empty_cache()\n",
        "      result = pipe(prompt_embeds=prompt_embeds, image=img, strength = img2img_strength, num_inference_steps=steps, guidance_scale=gscale, negative_prompt=negs, generator=generator).images[0]\n",
        "\n",
        "  if sd_type == \"Stable Diffusion XL (Turbo)\":\n",
        "    if show_diffusion:\n",
        "      torch.cuda.empty_cache()\n",
        "      result = pipe(prompt_embeds=conditioning, pooled_prompt_embeds=pooled, callback_on_step_end=decode_tensors, callback_on_step_end_tensor_inputs=[\"latents\"], image=img, strength = img2img_strength, num_inference_steps=steps, guidance_scale=gscale, negative_prompt=negs, generator=generator).images[0]\n",
        "    else:\n",
        "      torch.cuda.empty_cache()\n",
        "      result = pipe(prompt_embeds=conditioning, pooled_prompt_embeds=pooled, image=img, strength = img2img_strength, num_inference_steps=steps, guidance_scale=gscale, negative_prompt=negs, generator=generator).images[0]\n",
        "\n",
        "  clear_output()\n",
        "  print(\"#\" * max_length_string )\n",
        "  print(\"# Текущая модель Stable Diffusion: \" + current_checkpoint)\n",
        "  if use_lora:\n",
        "    if lora_url == \"\" and lora_path and weight_name:\n",
        "      output.append(\"# Текущая модель LoRA: \" + lora_path)\n",
        "    elif lora_url and lora_path == \"\" and weight_name == \"\":\n",
        "      output.append(\"# Текущая модель LoRA: \" + downloaded_lora_basename)\n",
        "  print(\"# Текущий стиль: \" + styles)\n",
        "  print(\"# Промпт: \" + prompt_display)\n",
        "  print(\"# Негативный промпт: \" + negs_display)\n",
        "  print(\"# Разрешение: \" + str(img_width) + \"x\" + str(img_height))\n",
        "  print(\"# Сила: \" + str(img2img_strength))\n",
        "  if not randomness:\n",
        "    print(\"# Seed этой генерации: \" + str(seed) + \"\\n\" + (\"#\" * max_length_string ))\n",
        "  elif randomness:\n",
        "    print(\"# Seed этой генерации: \" + str(current_seed) + \"\\n\" + (\"#\" * max_length_string ))\n",
        "\n",
        "  if use_gdrive:\n",
        "    today = str(date.today())\n",
        "    if not os.path.exists(\"/content/gdrive/MyDrive/SDOutput/\" + today):\n",
        "      os.makedirs(\"/content/gdrive/MyDrive/SDOutput/\" + today, exist_ok=True)\n",
        "    time = datetime.now()\n",
        "    time = str(time.strftime(\"%H-%M-%S\"))\n",
        "    file_name = time + \"_\" + \"seed_\" + str(current_seed) + \"_image\" + \"_img2imged.png\"\n",
        "    file_name = \"/content/gdrive/MyDrive/SDOutput/\" + today + \"/\" + file_name\n",
        "    result.save(file_name)\n",
        "    print(\"Сохранено: \" + file_name)\n",
        "\n",
        "  display( make_image_grid([img, result], rows=1, cols=2) )\n",
        "else:\n",
        "  print(\"Отсутствует изображение для генерации :(\")"
      ],
      "metadata": {
        "id": "kbebpfrLohQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Загрузка изображений для модуля Inpainting\n",
        "print(\"Выберите исходное изображение: \")\n",
        "inpaint_image = files.upload()\n",
        "print(\"Выберите изображение маски: \")\n",
        "inpaint_mask =  files.upload()\n",
        "\n",
        "inpaint_image_key = list(inpaint_image.keys())[0]\n",
        "inpaint_mask_image_key = list(inpaint_mask.keys())[0]\n",
        "inpaint_image_data = inpaint_image[inpaint_image_key]\n",
        "inpaint_mask_image_data = inpaint_mask[inpaint_mask_image_key]\n",
        "inpaint_image = Image.open(io.BytesIO(inpaint_image_data)).convert('RGB')\n",
        "inpaint_mask_image = Image.open(io.BytesIO(inpaint_mask_image_data)).convert('RGB')\n",
        "inpaint_image_width, inpaint_image_height = inpaint_image.size\n",
        "inpaint_image_mask_width, inpaint_image_mask_height = inpaint_mask_image.size"
      ],
      "metadata": {
        "cellView": "form",
        "id": "x0hV1I-eQTMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Inpainting (Генерация изображения из другого изображения с использованием маски): { form-width: \"10%\", display-mode: \"form\" }\n",
        "# @markdown <-- Начать генерацию\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown Сила:\n",
        "\n",
        "# @markdown Чем ниже значене, тем ближе генерация будет к изображению, которое вы загрузили. Чем больше значение, тем сильнее нейросеть будет креативничать.\n",
        "\n",
        "inpaint_strength = 1 # @param {type:\"slider\", min:0.1, max:1.0, step:0.1}\n",
        "\n",
        "# @markdown Силу нужно комбинировать с шагами. Итоговое количество шагов для генерации шума рассчитывается по формуле (Шаги * Сила).\n",
        "\n",
        "# @markdown Шаги:\n",
        "steps = 25 # @param {type:\"number\"}\n",
        "# @markdown ---\n",
        "# @markdown Показывать диффузию в реальном времени?\n",
        "show_diffusion = True # @param {type:\"boolean\"}\n",
        "# @markdown ---\n",
        "# @markdown При рисовании маски помните, что чёрные области игнорируются нейросетью, а белые - нет. Размытия белых областей в масках тоже поддерживаются.\n",
        "\n",
        "ddpm = DDPMScheduler.from_pretrained(current_checkpoint, subfolder=\"scheduler\")\n",
        "ddim = DDIMScheduler.from_pretrained(current_checkpoint, subfolder=\"scheduler\")\n",
        "pndm = PNDMScheduler.from_pretrained(current_checkpoint, subfolder=\"scheduler\")\n",
        "lms = LMSDiscreteScheduler.from_pretrained(current_checkpoint, subfolder=\"scheduler\")\n",
        "euler_anc = EulerAncestralDiscreteScheduler.from_pretrained(current_checkpoint, subfolder=\"scheduler\")\n",
        "euler = EulerDiscreteScheduler.from_pretrained(current_checkpoint, subfolder=\"scheduler\")\n",
        "dpm = DPMSolverMultistepScheduler.from_pretrained(current_checkpoint, subfolder=\"scheduler\")\n",
        "\n",
        "run_chkpt(current_checkpoint, lora_path, use_lora, \"inpainting\")\n",
        "\n",
        "if inpaint_image and inpaint_mask:\n",
        "\n",
        "  if sd_type == \"Stable Diffusion 1.5/2.0\":\n",
        "    compel_proc = Compel(tokenizer=pipe.tokenizer, text_encoder=pipe.text_encoder)\n",
        "    prompt_embeds = compel_proc(prompt)\n",
        "\n",
        "  if sd_type == \"Stable Diffusion XL (Turbo)\":\n",
        "    compel = Compel(\n",
        "      tokenizer=[pipe.tokenizer, pipe.tokenizer_2] ,\n",
        "      text_encoder=[pipe.text_encoder, pipe.text_encoder_2],\n",
        "      returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
        "      requires_pooled=[False, True]\n",
        "    )\n",
        "    conditioning, pooled = compel(prompt)\n",
        "  prompt_display = '\\n'.join([prompt[i:i+60] for i in range(0, len(prompt), 60)])\n",
        "  negs_display = '\\n'.join([negs[i:i+60] for i in range(0, len(negs), 60)])\n",
        "  output = [\n",
        "      \"# Текущая модель Stable Diffusion: \" + current_checkpoint,\n",
        "  ]\n",
        "  if lora_url == \"\" and lora_path and weight_name:\n",
        "    output.append(\"# Текущая модель LoRA: \" + lora_path)\n",
        "  elif lora_url and lora_path == \"\" and weight_name == \"\":\n",
        "    output.append(\"# Текущая модель LoRA: \" + downloaded_lora_basename)\n",
        "  output.extend([\n",
        "      \"# Текущий стиль: \" + styles,\n",
        "      \"# Промпт: \" + prompt_display,\n",
        "      \"# Негативный промпт: \" + negs_display,\n",
        "      \"# Разрешение изображения: \" + str(inpaint_image_width) + \"x\" + str(inpaint_image_height),\n",
        "      \"# Разрешение маски: \" + str(inpaint_image_mask_width) + \"x\" + str(inpaint_image_mask_height),\n",
        "      \"# Сила: \" + str(inpaint_strength)\n",
        "  ])\n",
        "  max_length_string = 70\n",
        "\n",
        "  print(\"#\" * max_length_string )\n",
        "  for item in output:\n",
        "    print(item)\n",
        "\n",
        "  if not randomness:\n",
        "    generator = torch.Generator(current_device).manual_seed(seed)\n",
        "    print(\"# Seed этой генерации: \" + str(seed) + \"\\n\" + (\"#\" * max_length_string) )\n",
        "  elif randomness:\n",
        "    current_seed = torch.Generator(current_device).seed()\n",
        "    generator = torch.Generator(current_device).manual_seed(current_seed)\n",
        "    print(\"# Seed этой генерации: \" + str(current_seed) + \"\\n\" + (\"#\" * max_length_string ))\n",
        "\n",
        "  if sd_type == \"Stable Diffusion 1.5/2.0\":\n",
        "    if show_diffusion:\n",
        "      torch.cuda.empty_cache()\n",
        "      result = pipe(prompt_embeds=prompt_embeds, callback_on_step_end=decode_tensors, callback_on_step_end_tensor_inputs=[\"latents\"], image=inpaint_image, mask_image=inpaint_mask_image, width=inpaint_image_width, height=inpaint_image_height, strength = inpaint_strength, num_inference_steps=steps, guidance_scale=gscale, negative_prompt=negs, generator=generator).images[0]\n",
        "    else:\n",
        "      torch.cuda.empty_cache()\n",
        "      result = pipe(prompt_embeds=prompt_embeds, image=inpaint_image, mask_image=inpaint_mask_image, width=inpaint_image_width, height=inpaint_image_height, strength = inpaint_strength, num_inference_steps=steps, guidance_scale=gscale, negative_prompt=negs, generator=generator).images[0]\n",
        "\n",
        "  if sd_type == \"Stable Diffusion XL (Turbo)\":\n",
        "    if show_diffusion:\n",
        "      torch.cuda.empty_cache()\n",
        "      result = pipe(prompt_embeds=conditioning, pooled_prompt_embeds=pooled, callback_on_step_end=decode_tensors, callback_on_step_end_tensor_inputs=[\"latents\"], image=inpaint_image, mask_image=inpaint_mask_image, width=inpaint_image_width, height=inpaint_image_height, strength = inpaint_strength, num_inference_steps=steps, guidance_scale=gscale, negative_prompt=negs, generator=generator).images[0]\n",
        "    else:\n",
        "      torch.cuda.empty_cache()\n",
        "      result = pipe(prompt_embeds=conditioning, pooled_prompt_embeds=pooled, image=inpaint_image, mask_image=inpaint_mask_image, width=inpaint_image_width, height=inpaint_image_height, strength = inpaint_strength, num_inference_steps=steps, guidance_scale=gscale, negative_prompt=negs, generator=generator).images[0]\n",
        "\n",
        "  clear_output()\n",
        "  print(\"#\" * max_length_string )\n",
        "  print(\"# Текущая модель Stable Diffusion: \" + current_checkpoint)\n",
        "  if use_lora:\n",
        "    if lora_url == \"\" and lora_path and weight_name:\n",
        "      output.append(\"# Текущая модель LoRA: \" + lora_path)\n",
        "    elif lora_url and lora_path == \"\" and weight_name == \"\":\n",
        "      output.append(\"# Текущая модель LoRA: \" + downloaded_lora_basename)\n",
        "  print(\"# Текущий стиль: \" + styles)\n",
        "  print(\"# Промпт: \" + prompt_display)\n",
        "  print(\"# Негативный промпт: \" + negs_display)\n",
        "  print(\"# Разрешение изображения: \" + str(inpaint_image_width) + \"x\" + str(inpaint_image_height) )\n",
        "  print(\"# Разрешение маски: \" + str(inpaint_image_mask_width) + \"x\" + str(inpaint_image_mask_height) )\n",
        "  print(\"# Сила: \" + str(inpaint_strength))\n",
        "  if not randomness:\n",
        "    print(\"# Seed этой генерации: \" + str(seed) + \"\\n\" + (\"#\" * max_length_string ))\n",
        "  elif randomness:\n",
        "    print(\"# Seed этой генерации: \" + str(current_seed) + \"\\n\" + (\"#\" * max_length_string ))\n",
        "\n",
        "  if use_gdrive:\n",
        "    today = str(date.today())\n",
        "    if not os.path.exists(\"/content/gdrive/MyDrive/SDOutput/\" + today):\n",
        "      os.makedirs(\"/content/gdrive/MyDrive/SDOutput/\" + today, exist_ok=True)\n",
        "    time = datetime.now()\n",
        "    time = str(time.strftime(\"%H-%M-%S\"))\n",
        "    file_name = time + \"_\" + \"seed_\" + str(current_seed) + \"_image\" + \"_inpainted.png\"\n",
        "    file_name = \"/content/gdrive/MyDrive/SDOutput/\" + today + \"/\" + file_name\n",
        "    result.save(file_name)\n",
        "    print(\"Сохранено: \" + file_name)\n",
        "\n",
        "  display( make_image_grid([inpaint_image, inpaint_mask_image, result], rows=1, cols=3) )\n",
        "else:\n",
        "  print(\"Вы отменили загрузку изображения :(\")"
      ],
      "metadata": {
        "id": "ibVBEYWQo2jQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Vq2nSTBmoWq-"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}